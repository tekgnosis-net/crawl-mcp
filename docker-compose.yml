# Docker Compose file for crawl4ai-mcp server
# This configuration sets up the crawl4ai-mcp server in both STDIO and HTTP modes
# with environment variables optimized for headless browser operation in Docker.


services:
  crawl4ai-mcp:
    build: .
    image: crawl4ai-mcp:latest
    container_name: crawl4ai-mcp-server
    restart: unless-stopped
    
    # For STDIO mode (default)
    stdin_open: true
    tty: true
    
    # Environment variables
    environment:
      - FASTMCP_LOG_LEVEL=${FASTMCP_LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      # Headless browser optimization
      - CRAWL4AI_BROWSER_TYPE=${CRAWL4AI_BROWSER_TYPE:-chromium}
      - CRAWL4AI_HEADLESS=true
      - PLAYWRIGHT_BROWSERS_PATH=/ms-playwright
      - DISPLAY=:99
      # Chrome-specific flags for Docker (quoted because value contains spaces)
      - 'CHROME_FLAGS=--no-sandbox --disable-dev-shm-usage --disable-gpu --headless'
    
    # Optional: expose port for HTTP mode
    ports:
      - "5000:8000"
    
    # Optional: volume mount for persistent data
    volumes:
      - ./logs:/app/logs
      - ./cache:/app/cache
    
    # Health check
    healthcheck:
      test: ["CMD", "python", "-c", "import crawl4ai_mcp.server; print('OK')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Alternative configuration for HTTP mode
  crawl4ai-mcp-http:
    build: .
    image: crawl4ai-mcp:latest
    container_name: crawl4ai-mcp-http
    restart: unless-stopped
    
    environment:
      - FASTMCP_LOG_LEVEL=${FASTMCP_LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      # Headless browser optimization
      - CRAWL4AI_BROWSER_TYPE=${CRAWL4AI_BROWSER_TYPE:-chromium}
      - CRAWL4AI_HEADLESS=true
      - PLAYWRIGHT_BROWSERS_PATH=/ms-playwright
      - DISPLAY=:99
      # Chrome-specific flags for Docker (quoted because value contains spaces)
      - 'CHROME_FLAGS=--no-sandbox --disable-dev-shm-usage --disable-gpu --headless'
    
    ports:
      - "5001:8000"
    
    volumes:
      - ./logs:/app/logs
      - ./cache:/app/cache
    
    command: ["python", "-m", "crawl4ai_mcp.server", "--transport", "http", "--host", "0.0.0.0", "--port", "8000"]
    
    profiles:
      - http
    
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s